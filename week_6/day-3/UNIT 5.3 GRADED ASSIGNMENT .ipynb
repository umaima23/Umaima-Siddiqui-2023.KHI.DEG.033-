{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01a740b9-b00d-4fda-9c6c-69be7e487161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import string\n",
    "from IPython.display import clear_output, display\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    max,\n",
    "    min,\n",
    "    udf,\n",
    "    avg,\n",
    "    col\n",
    ")\n",
    "spark = SparkSession.builder.appName(\"Assignment\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10f84d9e-2634-4c9f-96db-7af9709fed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"header\", \"false\").csv(\"titanic.csv\")\n",
    "column_names = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp','Parch','Ticket','Fare','Cabin','Embarked','Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ced3d499-79eb-4641-9469-abdbdef99e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_df = updated_df.toDF(*column_names)\n",
    "updated_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f603ac83-d4f0-4d63-8c30-8ac0c08a3fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked',\n",
       " 'Timestamp']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df.schema.names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38cef0f0-7150-4c22-9e00-a1fac42a50c5",
   "metadata": {},
   "source": [
    "## For numerical columns, calculate minimum, maximum and average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c36f7a39-fdd7-4c27-a3d9-26984f0935c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf39c4df-34ab-47b1-90ca-373666910188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'PassengerId':\n",
      "  Minimum: 1.0\n",
      "  Maximum: 891.0\n",
      "  Average: 446.0\n",
      "\n",
      "Column 'Survived':\n",
      "  Minimum: 0.0\n",
      "  Maximum: 1.0\n",
      "  Average: 0.3838383838383838\n",
      "\n",
      "Column 'Pclass':\n",
      "  Minimum: 1.0\n",
      "  Maximum: 3.0\n",
      "  Average: 2.308641975308642\n",
      "\n",
      "Column 'Age':\n",
      "  Minimum: 0.0\n",
      "  Maximum: 80.0\n",
      "  Average: 29.679271708683473\n",
      "\n",
      "Column 'SibSp':\n",
      "  Minimum: 0.0\n",
      "  Maximum: 8.0\n",
      "  Average: 0.5230078563411896\n",
      "\n",
      "Column 'Parch':\n",
      "  Minimum: 0.0\n",
      "  Maximum: 6.0\n",
      "  Average: 0.38159371492704824\n",
      "\n",
      "Column 'Fare':\n",
      "  Minimum: 0.0\n",
      "  Maximum: 512.3292\n",
      "  Average: 32.2042079685746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "numerical_columns = [col_name for col_name, col_type in updated_df.dtypes if col_type in [\"int\", \"double\"]]\n",
    "\n",
    "statistics = {}\n",
    "for column in numerical_columns:\n",
    "    column_stats = updated_df.select(col(column)).describe().collect()\n",
    "    minimum = float(column_stats[3][column]) if column_stats[3][column] is not None else None\n",
    "    maximum = float(column_stats[4][column]) if column_stats[4][column] is not None else None\n",
    "    average = float(column_stats[1][column]) if column_stats[1][column] is not None else None\n",
    "    stats = {\n",
    "        \"minimum\": minimum,\n",
    "        \"maximum\": maximum,\n",
    "        \"average\": average\n",
    "    }\n",
    "    statistics[column] = stats\n",
    "\n",
    "# Print the calculated statistics\n",
    "for column, stats in statistics.items():\n",
    "    print(f\"Column '{column}':\")\n",
    "    print(f\"  Minimum: {stats['minimum']}\")\n",
    "    print(f\"  Maximum: {stats['maximum']}\")\n",
    "    print(f\"  Average: {stats['average']}\")\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c60ba0f9-f318-46bc-b5d6-af33b1b67581",
   "metadata": {},
   "source": [
    "## For categorical columns, create and apply UDF that will change the last letter of every word to “1”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3a6ff18-7968-4951-9910-4b028b380e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(PassengerId=1, Survived=0, Pclass=3, Name='Braund, Mr. Owen Harris', Sex='mal1', Age=22, SibSp=1, Parch=0, Ticket='A/5 21171', Fare=7.25, Cabin=None, Embarked='S', Timestamp=datetime.datetime(2020, 1, 1, 13, 45, 25))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def change_last_letter(x: str) -> StringType:\n",
    "    words = x.split()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = words[i][:-1] + \"1\"\n",
    "        return \" \".join(words)\n",
    "udf_change_last_letter = udf(change_last_letter, StringType())\n",
    "df = updated_df.withColumn(\"Sex\", udf_change_last_letter(col(\"Sex\")))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf08f227-a328-4681-a49b-63df448dfb2a",
   "metadata": {},
   "source": [
    "## Sort DataFrame by the first column and save the results to the Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "965227af-59d2-46c5-8248-8176881d30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.orderBy(df.columns[0])\n",
    "sorted_df.write.parquet(\"titanic_output_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
